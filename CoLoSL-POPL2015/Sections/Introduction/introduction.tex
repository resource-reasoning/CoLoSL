\section{Introduction}

%% Jules: be more general than just program logics? Model-checking,
%% etc.?


%\pg{This is what we should answer by the introduction: 
%What's the problem with the current state of the art?
%What is our solution?
%Why is the problem we're solving hard?
%How do we solve the challenges?
%Why do we do better than existing work?
%What are the lessons learnt from the paper?}


A key difficulty in verifying properties of shared-memory concurrent
programs is to be able to reason compositionally about each thread in
isolation, even though in reality the correctness of the whole system
is the collaborative result of intricately intertwined actions of the
threads.  Such compositional reasoning is essential for verifying
large concurrent systems and for replicating a programmer's intuition
about why their implementations are correct. For sequential programs,
separation logic has demonstrated the importance of reasoning about
only the portions of the machine state (the resource) actually
accessed by programs. For concurrent programs, existing
techniques~\cite{lotsofthem} provide fine-grained compositional
reasoning about a global shared resource.

brittle, unnatural specifications. 

require global reasoning
about shared resource, even though a thread might only access a small
part of it.

This paper introduces the program logic \colosl, in which threads are
verified with respect to their \emph{subjective views}. Each
subjective (personalised) view provides a thread-specific description
of the shared state, comprising the partial shared resource necessary
for the thread to run and a thread-specific interference relation
describing how the thread and the environment can effect this partial
shared resource. Subjective views may arbitrarily overlap with each
other.  In particular, the interference relations expand and contract
with relation to the partial shared resource, as long as the projected
effect on the subjective view remains the same.  This flexibility
provides truly compositional proofs for shared-memory concurrency,
which we demonstrate on a range of examples including a concurrent
computation of the spanning tree of a graph.


%Driven by the ever-increasing need for concurrency in software,
%%  spurred by recent hardware developments, 
%program logics for shared-memory concurrency have progressed towards
%the twin ideals of fine-grain reasoning and compositionality. The
%former enables elegant proof techniques about increasingly subtle
%concurrency idioms~\cite{vv06popl,vv07msc,todo}, while the latter
%allows programs to be proved component-wise and their proofs to be
%reusable as-is in any client
%program~\cite{csl-tcs,cap-ecoop10,icap}.
%%  Central to these compositional verification frameworks is the
%% formalism used to describe both the state shared between program
%% threads and the possible interference on that state.
%%
%% dating back from Owicki~\cite{owicki}, and later Jones who
%% integrated the notion of interference in the logic
%% itself~\cite{rg}.
%% 
The recent formalism of Views~\cite{views} pinpoints a common
fundamental insight behind these program logics: assertions denote
\emph{views} of the concrete machine state for each thread, which
other threads cannot invalidate. Borrowing the vocabulary, existing
formalisms (with the notable exception of Local Rely
Guarantee~\cite{lrg}--henceforth LRG) require the view of all threads
to map to the same portion of concrete state. This impedes
compositionality: to use a given program specification in another
context, the current shared state has to match that of the existing
specification, instead of merely containing it.  While
compositionality calls for specifications that talk only about the
part of the state actually accessed by each thread (the thread's
\emph{subjective view} of the state), the rigidity of existing
frameworks forces us to adopt global specifications. Moreover, the
reasoning has to be robust against interferences from the environment
\emph{even on parts of the shared state not actually accessed by the
  current thread}. Finally, while in some examples one will know what
the entire global shared state is, this will not always be the case
(\textit{e.g.}, when proving code from a library, independently of any
client). For shared-memory reasoning to naturally apply to incomplete
code and scale to large programs, better techniques are needed.

%% Consider for instance
%% a program where threads operate on subgraphs of a global graph.

This paper presents the program logic \colosl, which achieves
compositional reasoning for concurrent programs by enabling
\emph{subjective} views of the shared state. Subjective views may be
composed arbitrarily and manipulated so as to retain only the portions
of local and shared state actually accessed by each thread in the
program, and to consider only the interferences relevant to that piece
of shared state. \colosl achieves a greater degree of compositionality
than existing work by enabling \emph{finer-grained} sharing: the
program logic can consider that threads share only what is relevant to
their function, a key ingredient of compositionality.

%%  dubbed their \emph{subjective states}.  One may then reuse these
%%   specifications in the context of any larger local state (as is
%%   standard in separation logic~\cite{rey02}), and, crucially for
%%   compositional reasoning about concurrent programs, any larger
%%   shared state. The subjective states of different threads in a
%%   program are allowed to overlap arbitrarily, ensuring maximum
%%   reusability of proofs.

\colosl's subjective views are of the form $\shared P I$ where $P$ is
a formula and $I$ is the \emph{interference} described as a set of \emph{actions}. The  $\shared P I$ assertion means that the formula $P$ is true of \emph{some part} of the shared state, and that this part of the shared state is subject to the interference captured by $I$. The interference $I$ contains actions that describe how the shared state can be mutated by the environment (known in the literature as ``Rely''), as well as those actions that the current thread is allowed to perform (known as ``Guarantee'').  Four novel principles allow us to reason about this novel interpretation of shared state assertions in \colosl.

First, subjective views only capture fractions of the global shared
state relevant to the program at hand, and we can always zoom in
further on the subjective state:
\begin{align*}
  \label{eq:forget}
  \shared{P * Q}{I} &=> \shared{P}{I}  \tag{\forgetRule}
\end{align*}
This allows one to reuse specifications written from a subjective view
of the state in contexts where we know more about the share state.

Second, the $*$ connective of separation logic combines
subjective views by \emph{overlapping} them ($P ** Q$ denotes those
states that result from overlapping a state satisfying $P$ with one
satisfying $Q$):
\begin{align*}
  \label{eq:merge}
  \shared{P}{I_1} * \shared{Q}{I_2} &=> \shared{P \sepish Q}{I_1 \cup I_2} \tag{\mergeRule}
\end{align*}
Doing so also combines the interference relations. Pleasingly, the new
interference relation is simply the union of previous interferences.
Similarly, the subjective view can always be duplicated:
\begin{align*}
  \label{eq:split}
  \shared{P}{I} &=> \shared{P}{I} * \shared P I \tag{\copyRule}
\end{align*}
In combination with the usual law of parallel composition of
separation logic~\cite{csl-tcs}, this yields a powerful mechanism to
distribute the shared state between several threads:
\[
\infrule{Parallel}
        {\hoare{P_1}{\mathbb{P}_1}{Q_1}\\
          \hoare{P_2}{\mathbb{P}_2}{Q_2}}
        {\hoare{P_1 * P_2}{\mathbb{P}_1 || \mathbb{P}_2}{Q_1 * Q_2}}
        {}
\]


Third, a set of actions $I$ can be exchanged for any other $I'$ that
has the same projected effect on the subjective state $P$; when that
is the case, we write $ I \weakenIb{P} I'$ and say that the actions
are \emph{shifted}:
\begin{align*}
  \label{eq:shift}
  I \weakenIb{P} I'
  &\text{ implies }
  \shared{P}{I} ===> \shared{P}{I'}
  \tag{\shiftRule}
\end{align*}
This feature is in contrast with most existing formalisms, where the
interference relation is fixed for the proof of the whole program. The
semantic relation $\weakenIb{}$ is partially axiomitised so as to
reduce shifting proofs to simple logical entailments. While
incomplete, we found this axiomatisation to be enough for our
examples.

Finally, private resources can be incorporated into the shared state
together with new actions:
\begin{align}
  \label{eq:extend}
  P \containI I
  &\text{ implies }
  P ===>
  \exsts{\capAss{1}, \capAss{2}} \capAss{1} * \shared{P *
    \capAss{2}}{I}
  \tag{\extendRule}
\end{align}
The side condition $P \containI I$ ensures that the mutations
performed by actions in $I$ are confined to $P$. The existential
quantification of capabilities is to ensure the \emph{freshness} of
the generated capabilities. The main novelty of this rule is the fact
that new actions may refer to existing shared state. As we will see in
our example of concurrent set operations, this enable flexible and
powerful reasoning.
\azaleacomment{We have not said what capabilities are. This is a bit
  rushed. Also, are we going to replace $\capAss{}$ with tokens?}


We show soundness, it was really hard, involves very subtle stuff. 
Our soundness result is parametric in the underlying
  programming language and separation algebra of states. The four
  principles above are simple semantic consequences of our generic
  model of program states.

We evaluate \colosl on a range of key  examples. 
In 
\S\ref{sec:intuition}, we  motivate \colosl reasoning using 
a variant of the  token ring mutual exclusion algorithm [? ],
introduced by Dijkstra to illustrate distributed, global knowledge between
threads. The point is that, as well as local knowledge
about how the threads behave, the programmer also has global knowledge
about how the threads constrain each other. Our reasoning captures the
spirit of reasoning locally about individual threads at the same time
as retaining global knowledge about the overall thread behaviour. It
is a good  introductory example, as it uses all five \colosl
principles in a fundamental way. 
In \S\ref{sec:examples}, we 
study two further, more challenging examples. We verify an concurrent algorithm for
computing the spanning tree of a graph, illustrating how our reasoning
works on naturally shared data structures. Our  \colosl reasoning for
the concurrent algorithm 
is simpler than the proof of a sequential tree spanning algorithm
by Villard and ....~\cite{??}  because ......... We also study a concurrent set module
implemented using a hand-over-hand list-locking algorithm,
demonstrating that our proof of correctness of the implementation is
considerably simpler than reasoning using CAP. 










\paragraph{Related work}


\pgcomment{This should go at end of paper, then we can talk about
  fences.} 


Reasoning about concurrency: major advances since Owicki-Gries:
compositional reasoning, from the seminal paper by Jones~\cite{rg} on
the one hand, and O'Hearn~\cite{csl-orig,csl-tcs} on the other hand,
later fused together in a series of increasingly compositional
formalisms such as RGSep~\cite{viktor-marriage}, Local RG~\cite{lrg},
deny-guarantee~\cite{dg}, and the CAP
family~\cite{cap-ecoop10,icap,tada}, to name a few.

%% [have pictures of the shared state throughout the ages, like in the
%%   York talk? No: it's difficult to argue that the drawings accurately
%%   represent the logics RGSep and LRG...]

our boxes very different,  fences like LRG, now what to say about
abstraction and TaDA. 

In some way, this mirrors the progression w.r.t.\ compositionality of
reasoning about sequential programs with resources/heap: first Hoare
logic~\cite{hoarelogic} carry around the whole of the heap. Major
advances in compositionality for pointer programs via separation
logic~\cite{seplog}, which enables \emph{local} proofs where
irrelevant and disjoint pieces of state are \emph{framed}, recently
extended to programs manipulating data structures with intrinsic
sharing, such as graphs~\cite{ramification}.
